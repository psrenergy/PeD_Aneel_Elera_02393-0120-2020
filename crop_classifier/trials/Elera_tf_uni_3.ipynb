{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvwU9GO1oqz4"
      },
      "source": [
        "# Elera: reconhecimendo de cultivos irrigados\n",
        "## Arquitetura e validação de modelo\n",
        "\n",
        "Este notebook tem como objetivo o desenvolvimento e validação de uma rede neural artificial (ANN) capaz de identificar áreas de cultivo irrigadas e suas respectivas culturas, dentro do escopo de três categorias de interesse:\n",
        "* \"Cana-de-açúcar\": Áreas de cultivo de cana-de-açúcar irrigadas.\n",
        "* \"Soja\": Áreas de cultivo de soja irrigada, ou principalmente de outros cultivos irrigados localizados nas mesmas áreas que soja, mas em diferente sazonalidade. Exemplos comuns: milho e algodão.\n",
        "* \"Outras culturas perenes\": Categoria que abrange diversos cultivos irrigados, especialmente frutíferas.\n",
        "\n",
        "Parte dos dados aqui utilizados já foram pré-processados em etapas anteriores. Acesso aos scripts utilizados no processo estão disponíveis no repositório do projeto.\n",
        "\n",
        "Este notebook utiliza serviços da Google que demandam credenciamento, tal como Google Cloud e Google Earth Engine. O usuário precisará de credenciais próprias para executar certas rotinas aqui presentes.\n",
        "\n",
        "### Importação de bibliotecas\n",
        "\n",
        "Declaração de módulos externos que serão utilizados no notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fF3Du0pqcj-o"
      },
      "outputs": [],
      "source": [
        "#!pip install earthengine-api\n",
        "#!pip install folium\n",
        "#!pip install tensorflow\n",
        "#!pip install geemap\n",
        "import ee\n",
        "import tensorflow as tf\n",
        "#import geemap\n",
        "from google.cloud import storage\n",
        "import os\n",
        "import json\n",
        "from tensorflow.python.tools import saved_model_utils\n",
        "from tensorflow import keras\n",
        "import folium\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-mFC8o4oqyu"
      },
      "source": [
        "### Autenticação \n",
        "\n",
        "Ativação da API por meio de credenciais do usuário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5CtzYozcocA",
        "outputId": "e893d4d5-9f49-4a82-9445-4cd281035a23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<p>To authorize access needed by Earth Engine, open the following\n",
              "        URL in a web browser and follow the instructions:</p>\n",
              "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=VTFsPKDWXxkZWvMXoON7NtnSxFHKvX2OLWuYK0cds4o&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=VTFsPKDWXxkZWvMXoON7NtnSxFHKvX2OLWuYK0cds4o&code_challenge_method=S256</a></p>\n",
              "        <p>The authorization workflow will generate a code, which you\n",
              "        should paste in the box below</p>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Successfully saved authorization token.\n"
          ]
        }
      ],
      "source": [
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"pd-psr-elera-e8562bed1814.json\"\n",
        "service_account = 'rodrigobenoliel@pd-psr-elera.iam.gserviceaccount.com'\n",
        "credentials = ee.ServiceAccountCredentials(service_account, 'pd-psr-elera-e8562bed1814.json')\n",
        "ee.Initialize(credentials)\n",
        "storage_client = storage.Client.from_service_account_json('pd-psr-elera-e8562bed1814.json')\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D0hhlaKQZtlG"
      },
      "outputs": [],
      "source": [
        "table = ee.FeatureCollection(\"projects/pd-psr-elera/assets/PNRH_SUB1_1\")\n",
        "image_irrigated = ee.Image('projects/pd-psr-elera/assets/irrigadas_2020')\n",
        "studyArea = ee.FeatureCollection(table).geometry()\n",
        "START_DATE = '2020-07-01'\n",
        "END_DATE = '2020-07-30'\n",
        "\n",
        "\n",
        "def cloud_shadow_Mask(image):\n",
        "  qa = image.select('QA60')\n",
        "  cloud = qa.bitwiseAnd(1<<10).Or(qa.bitwiseAnd(1<<11))\n",
        "\n",
        "  mask2 = image.mask().reduce(ee.Reducer.min())\n",
        "  return image.updateMask(cloud.Not()).updateMask(mask2)\n",
        "\n",
        "image = ee.ImageCollection('COPERNICUS/S2_SR').filterBounds(studyArea).filterDate(START_DATE, END_DATE).map(cloud_shadow_Mask).median()\n",
        "\n",
        "image = image.reproject(\n",
        "      crs = image_irrigated.projection()\n",
        "    ).reduceResolution(\n",
        "      reducer = ee.Reducer.mean(),\n",
        "      maxPixels = 1024\n",
        "    )\n",
        "\n",
        "image = ee.Image('projects/pd-psr-elera/assets/sent2_30m_2020-07-01_2020-07-30')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "id": "JDbCUtN3aPsF",
        "outputId": "483e67f2-ea15-41f8-eb11-0acb979f079a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%3Cscript%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20L_NO_TOUCH%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L_DISABLE_3D%20%3D%20false%3B%0A%20%20%20%20%20%20%20%20%3C/script%3E%0A%20%20%20%20%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.6.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css%22/%3E%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cstyle%3E%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23map_b5d78be77fbd4e74b254c07fcb15e822%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%3C/style%3E%0A%20%20%20%20%20%20%20%20%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_b5d78be77fbd4e74b254c07fcb15e822%22%20%3E%3C/div%3E%0A%20%20%20%20%20%20%20%20%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20map_b5d78be77fbd4e74b254c07fcb15e822%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22map_b5d78be77fbd4e74b254c07fcb15e822%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20center%3A%20%5B0%2C%200%5D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoom%3A%201%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20preferCanvas%3A%20false%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29%3B%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20tile_layer_bcd6ba27f19c4695890129671aa9169c%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22https%3A//%7Bs%7D.tile.openstreetmap.org/%7Bz%7D/%7Bx%7D/%7By%7D.png%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22attribution%22%3A%20%22Data%20by%20%5Cu0026copy%3B%20%5Cu003ca%20href%3D%5C%22http%3A//openstreetmap.org%5C%22%5Cu003eOpenStreetMap%5Cu003c/a%5Cu003e%2C%20under%20%5Cu003ca%20href%3D%5C%22http%3A//www.openstreetmap.org/copyright%5C%22%5Cu003eODbL%5Cu003c/a%5Cu003e.%22%2C%20%22detectRetina%22%3A%20false%2C%20%22maxNativeZoom%22%3A%2018%2C%20%22maxZoom%22%3A%2018%2C%20%22minZoom%22%3A%200%2C%20%22noWrap%22%3A%20false%2C%20%22opacity%22%3A%201%2C%20%22subdomains%22%3A%20%22abc%22%2C%20%22tms%22%3A%20false%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_b5d78be77fbd4e74b254c07fcb15e822%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20tile_layer_1938ca7917ef4d188256c72c04e5d3be%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22https%3A//earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/107f6ed2b48a519b8247279d4493c9b9-2b235ec6909e79df9947b768d71a3e53/tiles/%7Bz%7D/%7Bx%7D/%7By%7D%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22attribution%22%3A%20%22Map%20Data%20%5Cu0026copy%3B%20%5Cu003ca%20href%3D%5C%22https%3A//earthengine.google.com/%5C%22%5Cu003eGoogle%20Earth%20Engine%5Cu003c/a%5Cu003e%22%2C%20%22detectRetina%22%3A%20false%2C%20%22maxNativeZoom%22%3A%2018%2C%20%22maxZoom%22%3A%2018%2C%20%22minZoom%22%3A%209%2C%20%22noWrap%22%3A%20false%2C%20%22opacity%22%3A%201%2C%20%22subdomains%22%3A%20%22abc%22%2C%20%22tms%22%3A%20false%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_b5d78be77fbd4e74b254c07fcb15e822%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20layer_control_7473007ada0c4ce0ae75fb88da0c9f78%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20base_layers%20%3A%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22openstreetmap%22%20%3A%20tile_layer_bcd6ba27f19c4695890129671aa9169c%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20overlays%20%3A%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22S2%20cloud-free%20mosaic%22%20%3A%20tile_layer_1938ca7917ef4d188256c72c04e5d3be%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L.control.layers%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_7473007ada0c4ce0ae75fb88da0c9f78.base_layers%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_7473007ada0c4ce0ae75fb88da0c9f78.overlays%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22autoZIndex%22%3A%20true%2C%20%22collapsed%22%3A%20true%2C%20%22position%22%3A%20%22topright%22%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%29.addTo%28map_b5d78be77fbd4e74b254c07fcb15e822%29%3B%0A%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x1ff0e8fc9d0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def add_ee_layer(self, ee_image_object, vis_params, name, show=True, opacity=1, min_zoom=0):\n",
        "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
        "  folium.raster_layers.TileLayer(\n",
        "      tiles=map_id_dict['tile_fetcher'].url_format,\n",
        "      attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "      name=name,\n",
        "      show=show,\n",
        "      opacity=opacity,\n",
        "      min_zoom=min_zoom,\n",
        "      overlay=True,\n",
        "      control=True\n",
        "      ).add_to(self)\n",
        "\n",
        "# Add the Earth Engine layer method to folium.\n",
        "folium.Map.add_ee_layer = add_ee_layer\n",
        "\n",
        "m = folium.Map(zoom_start=12)\n",
        "\n",
        "# Add layers to the folium map.\n",
        "m.add_ee_layer(image,\n",
        "                {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 2500, 'gamma': 1.1},\n",
        "                'S2 cloud-free mosaic', True, 1, 9)\n",
        "\n",
        "# Add a layer control panel to the map.\n",
        "m.add_child(folium.LayerControl())\n",
        "\n",
        "# Display the map.\n",
        "display(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd9vpy7WtnMn"
      },
      "source": [
        "### Leitura e processamento dos dados de entrada para o modelo\n",
        "\n",
        "Inclui acesso direto a assets do projeto no Google Earth Engine. São estes:\n",
        "\n",
        "* As áreas irrigadas de cultivo indefinido.\n",
        "* Imagens de satélite Landsat 8.\n",
        "* Fronteira que delimita a região de interesse do projeto.\n",
        "\n",
        "Seleciona-se bandas específicas das imagens de satélite, que incluem cores no espectro visível e infravermelho. Em seguida, sintetiza-se uma única imagem com base em uma janela temporal de 15 dias, período compatível com os dados de irrigação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ntxX-Z1TctpT"
      },
      "outputs": [],
      "source": [
        "#image = ee.Image(\"projects/pd-psr-elera/assets/Sentinel_2_cloud_free_2020-07-01_2020_07_15\")\n",
        "mapbiomas3 = ee.Image(\"projects/pd-psr-elera/assets/mapbiomas-brazil-collection-60-2020-0000000000-0000000000\")\n",
        "\n",
        "BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11','B12']\n",
        "image = image.select(BANDS)\n",
        "LABEL = 'class'\n",
        "N_LABELS = 5\n",
        "SCALE = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFFXIthfojzv"
      },
      "source": [
        "### Leitura de rótulos de referência a serem utilizados para treinamento do modelo\n",
        "\n",
        "Os seguintes dados consistem em polígonos rotulados nas categorias de interesse que foram previamente selecionados selecionados. Serão definidas duas coleções:\n",
        "* `data`: dados a serem usados para treinamento.\n",
        "* `data_test_simple`: dados a serem usados para validação.\n",
        "* `data_test`: banco de dados consideravelmente maior, que será usado para teste de desempenho do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R-C9LsgOc9Nj"
      },
      "outputs": [],
      "source": [
        "TILE_SCALE = 16\n",
        "data = ee.FeatureCollection('projects/pd-psr-elera/assets/uni_train_data_3')\n",
        "data = image.sampleRegions(\n",
        "    collection = data,\n",
        "    properties = [LABEL],\n",
        "    tileScale = TILE_SCALE,\n",
        "    #scale = SCALE\n",
        "    )\n",
        "\n",
        "data_test_simple = ee.FeatureCollection('projects/pd-psr-elera/assets/uni_val_data_3')\n",
        "data_test_simple = image.sampleRegions(\n",
        "    collection = data_test_simple,\n",
        "    properties = [LABEL],\n",
        "    tileScale = TILE_SCALE,\n",
        "    #scale = SCALE\n",
        "    )\n",
        "\n",
        "data_test_jp = ee.FeatureCollection('projects/pd-psr-elera/assets/uni_test_data_3_jp')\n",
        "data_test_jp = image.sampleRegions(\n",
        "    collection = data_test_jp,\n",
        "    properties = [LABEL],\n",
        "    tileScale = TILE_SCALE,\n",
        "    #scale = SCALE\n",
        "    )\n",
        "\n",
        "data_test_jb = ee.FeatureCollection('projects/pd-psr-elera/assets/uni_test_data_3_jb')\n",
        "data_test_jb = image.sampleRegions(\n",
        "    collection = data_test_jb,\n",
        "    properties = [LABEL],\n",
        "    tileScale = TILE_SCALE,\n",
        "    #scale = SCALE\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fv-79csw2Yy"
      },
      "source": [
        "### Exportação de dados para o Google Cloud\n",
        "\n",
        "Dados serão exportados para o Google Cloud em formato `TFRecord`. Este processo facilita o processo de conversão das estruturas de dados do Earth Engine para uma adequada ao framework TensorFlow, que será utilizada para o desenvolvimento do modelo.\n",
        "\n",
        "As seguintes rotinas demandam credenciais próprias do Google Cloud para execução.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YuHharTdN9J",
        "outputId": "c5f2f1cd-4eb4-48a2-9a14-8fa01ae7ffbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12', 'class']\n"
          ]
        }
      ],
      "source": [
        "# Your Earth Engine username.  This is used to import a classified image\n",
        "# into your Earth Engine assets folder.\n",
        "USER_NAME = 'rodrigobenoliel'\n",
        "\n",
        "FEATURE_NAMES = list(BANDS)\n",
        "FEATURE_NAMES.append(LABEL)\n",
        "\n",
        "# Cloud Storage bucket into which training, testing and prediction \n",
        "# datasets will be written.  You must be able to write into this bucket.\n",
        "OUTPUT_BUCKET = 'elera_classificator'\n",
        "\n",
        "# File names for the training and testing datasets.  These TFRecord files\n",
        "# will be exported from Earth Engine into the Cloud Storage bucket.\n",
        "TRAIN_FILE_PREFIX = 'uni_data_train_3'\n",
        "TEST_SIMPLE_FILE_PREFIX = 'uni_data_val_3'\n",
        "TEST_FILE_PREFIX_JP = 'uni_data_test_3_jp'\n",
        "TEST_FILE_PREFIX_JB = 'uni_data_test_3_jb'\n",
        "file_extension = '.tfrecord.gz'\n",
        "TRAIN_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TRAIN_FILE_PREFIX + file_extension\n",
        "TEST_SIMPLE_FILE_PATH = 'gs://' + OUTPUT_BUCKET + '/' + TEST_SIMPLE_FILE_PREFIX + file_extension\n",
        "TEST_FILE_PATH_JP = 'gs://' + OUTPUT_BUCKET + '/' + TEST_FILE_PREFIX_JP + file_extension\n",
        "TEST_FILE_PATH_JB = 'gs://' + OUTPUT_BUCKET + '/' + TEST_FILE_PREFIX_JB + file_extension\n",
        "\n",
        "\n",
        "\n",
        "# Create the tasks.\n",
        "training_task = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=data,\n",
        "  description='Training Export',\n",
        "  fileNamePrefix=TRAIN_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)\n",
        "\n",
        "testing_simple_task = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=data_test_simple,\n",
        "  description='Validation Export',\n",
        "  fileNamePrefix=TEST_SIMPLE_FILE_PREFIX,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)\n",
        "\n",
        "testing_task_jp = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=data_test_jp,\n",
        "  description='Testing Export',\n",
        "  fileNamePrefix=TEST_FILE_PREFIX_JP,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)\n",
        "\n",
        "testing_task_jb = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=data_test_jb,\n",
        "  description='Testing Export',\n",
        "  fileNamePrefix=TEST_FILE_PREFIX_JB,\n",
        "  bucket=OUTPUT_BUCKET,\n",
        "  fileFormat='TFRecord',\n",
        "  selectors=FEATURE_NAMES)\n",
        "\n",
        "print(FEATURE_NAMES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozO_ZMBcyM2P"
      },
      "source": [
        "Execução da exportação, este processo pode levar alguns segundos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ZV9dGwU1dUoQ"
      },
      "outputs": [],
      "source": [
        "# Start the tasks.\n",
        "testing_simple_task.start()\n",
        "training_task.start()\n",
        "testing_task_jp.start()\n",
        "testing_task_jb.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74TxyK_cgUMX",
        "outputId": "5740fca5-7a5c-49f7-b27b-7814ea775656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Polling for task (id: DFISUW5DDXLLTVUA6UMNPOBW).\n",
            "Done with image export.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "while testing_task_jb.active():\n",
        "  print('Polling for task (id: {}).'.format(testing_task_jb.id))\n",
        "  time.sleep(5)\n",
        "print('Done with image export.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnjr1jfJyVxk"
      },
      "source": [
        "### Leitura de dados em formato TFRecord\n",
        "\n",
        "Releitura dos dados no formato mais conveniente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFTcsUxhdWvj",
        "outputId": "cdb233fd-05f0-4afb-8955-a3ab4fc5f026"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'\\n\\xb6\\x01\\n\\x0e\\n\\x02B2\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x80\\xd0C\\n\\x0e\\n\\x02B3\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x80$D\\n\\x0e\\n\\x02B4\\x12\\x08\\x12\\x06\\n\\x04\\x00\\xc0?D\\n\\x0e\\n\\x02B5\\x12\\x08\\x12\\x06\\n\\x04\\x00\\xa0\\x90D\\n\\x0e\\n\\x02B6\\x12\\x08\\x12\\x06\\n\\x04\\x00\\xa0\\xe6D\\n\\x0e\\n\\x02B7\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x90\\x04E\\n\\x0e\\n\\x02B8\\x12\\x08\\x12\\x06\\n\\x04\\x00 \\x07E\\n\\x0f\\n\\x03B8A\\x12\\x08\\x12\\x06\\n\\x04\\x00\\xf0\\x12E\\n\\x0f\\n\\x03B11\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x90\"E\\n\\x0f\\n\\x03B12\\x12\\x08\\x12\\x06\\n\\x04\\x00\\xe0\\xcdD\\n\\x11\\n\\x05class\\x12\\x08\\x12\\x06\\n\\x04\\x00\\x00\\x00\\x00', shape=(), dtype=string)\n",
            "<class 'tensorflow.python.data.ops.readers.TFRecordDatasetV2'>\n"
          ]
        }
      ],
      "source": [
        "# Create a dataset from the TFRecord file in Cloud Storage.\n",
        "train_dataset = tf.data.TFRecordDataset(TRAIN_FILE_PATH, compression_type='GZIP')\n",
        "# Print the first record to check.\n",
        "print(iter(train_dataset).next())\n",
        "print(type(train_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9-phbQ-zB4a"
      },
      "source": [
        "Definição de metadados dos parâmetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaK_ELftdYjZ",
        "outputId": "b837605e-7c10-479f-d5f7-e04b6b63b93d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'B2': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'B3': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'B4': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'B5': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'B6': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'B7': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'B8': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'B8A': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'B11': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'B12': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None), 'class': FixedLenFeature(shape=[1], dtype=tf.float32, default_value=None)}\n"
          ]
        }
      ],
      "source": [
        "# List of fixed-length features, all of which are float32.\n",
        "columns = [\n",
        "  tf.io.FixedLenFeature(shape=[1], dtype=tf.float32) for k in FEATURE_NAMES\n",
        "]\n",
        "\n",
        "# Dictionary with names as keys, features as values.\n",
        "features_dict = dict(zip(FEATURE_NAMES, columns))\n",
        "\n",
        "print(features_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV_ny7QYzMSa"
      },
      "source": [
        "Definição de funções úteis para formatação dos dados e preparação para seu consumo pelo modelo. Funções são aplicadas aos dados de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM_c2jo2daJ5",
        "outputId": "526cb119-1d18-46fd-eb8a-83a940379834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'B11': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2601.], dtype=float32)>, 'B12': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1647.], dtype=float32)>, 'B2': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([417.], dtype=float32)>, 'B3': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([658.], dtype=float32)>, 'B4': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([767.], dtype=float32)>, 'B5': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1157.], dtype=float32)>, 'B6': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1845.], dtype=float32)>, 'B7': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2121.], dtype=float32)>, 'B8': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2162.], dtype=float32)>, 'B8A': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2351.], dtype=float32)>}, <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0])>)\n"
          ]
        }
      ],
      "source": [
        "def parse_tfrecord(example_proto):\n",
        "  \"\"\"The parsing function.\n",
        "\n",
        "  Read a serialized example into the structure defined by featuresDict.\n",
        "\n",
        "  Args:\n",
        "    example_proto: a serialized Example.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of the predictors dictionary and the label, cast to an `int32`.\n",
        "  \"\"\"\n",
        "  parsed_features = tf.io.parse_single_example(example_proto, features_dict)\n",
        "  labels = parsed_features.pop(LABEL)\n",
        "  return parsed_features, tf.cast(labels, tf.int32)\n",
        "\n",
        "# Map the function over the dataset.\n",
        "parsed_dataset = train_dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
        "\n",
        "# Print the first parsed record to check.\n",
        "print(iter(parsed_dataset).next())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9Y4PQU5diJJ",
        "outputId": "f27575d1-03fe-443b-c612-955db3084a12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(1, 1, 10), dtype=float32, numpy=\n",
            "array([[[ 417.,  658.,  767., 1157., 1845., 2121., 2162., 2351., 2601.,\n",
            "         1647.]]], dtype=float32)>, <tf.Tensor: shape=(1, 1, 5), dtype=float32, numpy=array([[[1., 0., 0., 0., 0.]]], dtype=float32)>)\n",
            "n rows 395654\n",
            "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n"
          ]
        }
      ],
      "source": [
        "# Keras requires inputs as a tuple.  Note that the inputs must be in the\n",
        "# right shape.  Also note that to use the categorical_crossentropy loss,\n",
        "# the label needs to be turned into a one-hot vector.\n",
        "def to_tuple(inputs, label):\n",
        "  values = []\n",
        "  for band in BANDS:\n",
        "    values.append(inputs[band])\n",
        "  return (tf.expand_dims(tf.transpose(values), 1),\n",
        "          tf.expand_dims(tf.one_hot(indices=label, depth=N_LABELS),1))\n",
        "\n",
        "# Map the to_tuple function, shuffle and batch.\n",
        "input_dataset_unbatched = parsed_dataset.map(to_tuple)\n",
        "\n",
        "print(iter(input_dataset_unbatched).next())\n",
        "batch_size = 128\n",
        "data_size = 395654\n",
        "print(\"n rows\", data_size)\n",
        "input_dataset = input_dataset_unbatched.shuffle(140223).batch(batch_size)\n",
        "print(type(input_dataset_unbatched))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Zt4CD3zil3"
      },
      "source": [
        "### Definição do modelo\n",
        "\n",
        "Definição da arquitetura da ANN e inicialização do seu treinamento e validação. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivcZC9H0dxS1",
        "outputId": "7312e167-65cb-4266-f12b-da6880479fe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_1 (Batc  (None, None, None, 10)   40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, None, None, 128)   1408      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, None, None, 128)   0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, None, None, 128)   16512     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, None, None, 128)   16512     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, None, None, 128)   0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, None, None, 5)     645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,117\n",
            "Trainable params: 35,097\n",
            "Non-trainable params: 20\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "5352/5352 [==============================] - 60s 8ms/step - loss: 0.2631 - accuracy: 0.9175 - val_loss: 0.5292 - val_accuracy: 0.8490\n",
            "Epoch 2/10\n",
            "5352/5352 [==============================] - 61s 8ms/step - loss: 0.2001 - accuracy: 0.9347 - val_loss: 0.5037 - val_accuracy: 0.8602\n",
            "Epoch 3/10\n",
            "5352/5352 [==============================] - 61s 8ms/step - loss: 0.1819 - accuracy: 0.9413 - val_loss: 0.5003 - val_accuracy: 0.8608\n",
            "Epoch 4/10\n",
            "5352/5352 [==============================] - 59s 8ms/step - loss: 0.1732 - accuracy: 0.9441 - val_loss: 0.5137 - val_accuracy: 0.8552\n",
            "Epoch 5/10\n",
            "5352/5352 [==============================] - 60s 8ms/step - loss: 0.1673 - accuracy: 0.9462 - val_loss: 0.5021 - val_accuracy: 0.8575\n",
            "Epoch 6/10\n",
            "5352/5352 [==============================] - 59s 8ms/step - loss: 0.1622 - accuracy: 0.9476 - val_loss: 0.5148 - val_accuracy: 0.8539\n",
            "Epoch 7/10\n",
            "5352/5352 [==============================] - 61s 8ms/step - loss: 0.1589 - accuracy: 0.9488 - val_loss: 0.5136 - val_accuracy: 0.8529\n",
            "Epoch 8/10\n",
            "5352/5352 [==============================] - 64s 9ms/step - loss: 0.1555 - accuracy: 0.9496 - val_loss: 0.5019 - val_accuracy: 0.8577\n",
            "Epoch 9/10\n",
            "5352/5352 [==============================] - 64s 9ms/step - loss: 0.1526 - accuracy: 0.9502 - val_loss: 0.4962 - val_accuracy: 0.8582\n",
            "Epoch 10/10\n",
            "5352/5352 [==============================] - 59s 8ms/step - loss: 0.1522 - accuracy: 0.9504 - val_loss: 0.4849 - val_accuracy: 0.8603\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1ff16196b50>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([ \n",
        "    tf.keras.layers.Input((None, None, len(BANDS))),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    #tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    #tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    ##tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    #tf.keras.layers.Dropout(0.1),\n",
        "    tf.keras.layers.Dense(N_LABELS, activation=tf.nn.softmax)\n",
        "    ])\n",
        "\n",
        "test_simple_dataset = (\n",
        "  tf.data.TFRecordDataset(TEST_SIMPLE_FILE_PATH, compression_type='GZIP')\n",
        "    .map(parse_tfrecord, num_parallel_calls=5)\n",
        "    .map(to_tuple)\n",
        "    .shuffle(140223)\n",
        "    .batch(32))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#checkpoint_filepath = '/tmp/checkpoint' \n",
        "#import datetime\n",
        "#log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "#%rm -rf \"logs\"\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "#model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( filepath=checkpoint_filepath, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True)\n",
        "print(model.summary())\n",
        "#%reload_ext tensorboard\n",
        "model.fit(x=input_dataset, epochs=10, validation_data = test_simple_dataset)#, steps_per_epoch=data_size//batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QFAyOzzUCng"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO2v56w9_biU"
      },
      "source": [
        "### Exportação do modelo para o Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xunsId21vqZj",
        "outputId": "355a3bb5-247d-42ea-e92f-9eb7200377e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: gs://elera_classificator/uni_model_3/assets\n"
          ]
        }
      ],
      "source": [
        "MODEL_DIR = 'gs://' + OUTPUT_BUCKET + '/uni_model_3'\n",
        "model.save(MODEL_DIR, save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "2hiDT3dRxWrM",
        "outputId": "ac88b9c8-739e-40a2-dfd0-755001f4c49c"
      },
      "outputs": [
        {
          "ename": "UnimplementedError",
          "evalue": "File system scheme 'gs' not implemented (file: 'gs://elera_classificator/uni_model_3')",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[1;32mC:\\Users\\RODRIG~1\\AppData\\Local\\Temp/ipykernel_20012/3004037772.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mMODEL_DIR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'gs://'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mOUTPUT_BUCKET\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/uni_model_3'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model_plot.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mfile_exists_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    290\u001b[0m   \"\"\"\n\u001b[0;32m    291\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0m_pywrap_file_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileExists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_to_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mUnimplementedError\u001b[0m: File system scheme 'gs' not implemented (file: 'gs://elera_classificator/uni_model_3')"
          ]
        }
      ],
      "source": [
        "MODEL_DIR = 'gs://' + OUTPUT_BUCKET + '/uni_model_3'\n",
        "model = keras.models.load_model(MODEL_DIR)\n",
        "\n",
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGzY0SKK_kd2"
      },
      "source": [
        "### Testando modelo com banco de dados de teste\n",
        "\n",
        "Esta etapa tem como objetivo testar um desempenho do modelo sob uma demanda mais estressante."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQfbAqwYBwn4",
        "outputId": "c321dac2-b0fe-40ca-874d-e8aa2272da9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'B11': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([3490.5], dtype=float32)>, 'B12': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2202.], dtype=float32)>, 'B2': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([602.], dtype=float32)>, 'B3': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([870.5], dtype=float32)>, 'B4': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1182.5], dtype=float32)>, 'B5': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1575.], dtype=float32)>, 'B6': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2101.5], dtype=float32)>, 'B7': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2376.], dtype=float32)>, 'B8': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2573.], dtype=float32)>, 'B8A': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2768.], dtype=float32)>}, <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>)\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1, 5), dtype=tf.float32, name=None))>\n",
            "7150/7150 [==============================] - 102s 13ms/step - loss: 0.4543 - accuracy: 0.8513\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.454293817281723, 0.8512747883796692]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_DIR = 'gs://' + OUTPUT_BUCKET + '/uni_model_3'\n",
        "model = keras.models.load_model(MODEL_DIR)\n",
        "data_in = tf.data.TFRecordDataset(TEST_FILE_PATH_JP, compression_type='GZIP').map(parse_tfrecord, num_parallel_calls=5)\n",
        "print(iter(data_in).next())\n",
        "eval_data = (data_in\n",
        "    .map(to_tuple)\n",
        "    .shuffle(140223)\n",
        "    .batch(128))\n",
        "print(eval_data)\n",
        "model.evaluate(eval_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX9h1AHlT4tZ",
        "outputId": "9855fab6-9ae5-453c-a38e-919197c5eeb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "({'B11': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2670.5], dtype=float32)>, 'B12': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1511.5], dtype=float32)>, 'B2': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([285.], dtype=float32)>, 'B3': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([485.], dtype=float32)>, 'B4': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([468.5], dtype=float32)>, 'B5': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([914.5], dtype=float32)>, 'B6': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1796.5], dtype=float32)>, 'B7': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2178.], dtype=float32)>, 'B8': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2389.5], dtype=float32)>, 'B8A': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2623.5], dtype=float32)>}, <tf.Tensor: shape=(1,), dtype=int32, numpy=array([0], dtype=int32)>)\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1, 5), dtype=tf.float32, name=None))>\n",
            "7359/7359 [==============================] - 105s 13ms/step - loss: 0.4708 - accuracy: 0.8594\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.4708397686481476, 0.859380304813385]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MODEL_DIR = 'gs://' + OUTPUT_BUCKET + '/uni_model_3'\n",
        "model = keras.models.load_model(MODEL_DIR)\n",
        "data_in = tf.data.TFRecordDataset(TEST_FILE_PATH_JB, compression_type='GZIP').map(parse_tfrecord, num_parallel_calls=5)\n",
        "print(iter(data_in).next())\n",
        "eval_data = (data_in\n",
        "    .map(to_tuple)\n",
        "    .shuffle(140223)\n",
        "    .batch(128))\n",
        "print(eval_data)\n",
        "model.evaluate(eval_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "P83GSq0N83LF",
        "outputId": "5198e2f7-8a4a-4258-8d63-8ebaee9b2364"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-cf48a56332c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mMODEL_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mOUTPUT_BUCKET\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/uni_model_2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1980\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "MODEL_DIR = 'gs://' + OUTPUT_BUCKET + '/uni_model_2'\n",
        "model = keras.models.load_model(MODEL_DIR)\n",
        "y_pred = model.predict(eval_data)\n",
        "y_true = [value[1].numpy()[0][0][0] for value in eval_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBaBst1a_hvJ"
      },
      "outputs": [],
      "source": [
        "y_pred = [np.argmax(pred) for pred in y_pred]\n",
        "con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()\n",
        "sns.heatmap(con_mat, annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ0e4W9p40bO"
      },
      "source": [
        "### EEfication do modelo\n",
        "\n",
        "Este processo consiste na adaptação do modelo para que este possa ser exportado para a Google AI Platform, e em seguida possa ser utilizado diretamente por métodos do Google Earth Engine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSHwJzj_0dzh",
        "outputId": "be3aec48-cf22-466f-9ab6-c46104285c6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_6': name: \"serving_default_input_6:0\"\n",
            "dtype: DT_FLOAT\n",
            "tensor_shape {\n",
            "  dim {\n",
            "    size: -1\n",
            "  }\n",
            "  dim {\n",
            "    size: -1\n",
            "  }\n",
            "  dim {\n",
            "    size: -1\n",
            "  }\n",
            "  dim {\n",
            "    size: 10\n",
            "  }\n",
            "}\n",
            "}\n",
            "'{\"serving_default_input_6:0\": \"array\"}'\n",
            "'{\"StatefulPartitionedCall:0\": \"class\"}'\n"
          ]
        }
      ],
      "source": [
        "OUTPUT_BUCKET = 'elera_classificator'\n",
        "MODEL_DIR = 'gs://' + OUTPUT_BUCKET + '/uni_model_3'\n",
        "model = keras.models.load_model(MODEL_DIR)\n",
        "SERV_ACC = \"rodrigobenoliel@pd-psr-elera.iam.gserviceaccount.com\"\n",
        "\n",
        "meta_graph_def = saved_model_utils.get_meta_graph_def(MODEL_DIR, 'serve')\n",
        "inputs = meta_graph_def.signature_def['serving_default'].inputs\n",
        "outputs = meta_graph_def.signature_def['serving_default'].outputs\n",
        "# Just get the first thing(s) from the serving signature def.  i.e. this\n",
        "# model only has a single input and a single output.\n",
        "input_name = None\n",
        "for k,v in inputs.items():\n",
        "  input_name = v.name\n",
        "  break\n",
        "print(inputs)\n",
        "\n",
        "\n",
        "output_name = None\n",
        "for k,v in outputs.items():\n",
        "  output_name = v.name\n",
        "  break\n",
        "\n",
        "# Make a dictionary that maps Earth Engine outputs and inputs to\n",
        "# AI Platform inputs and outputs, respectively.\n",
        "input_dict = \"'\" + json.dumps({input_name: \"array\"}) + \"'\"\n",
        "output_dict = \"'\" + json.dumps({output_name: \"class\"}) + \"'\"\n",
        "print(input_dict)\n",
        "print(output_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSHXTAN10oXC",
        "outputId": "3c7bf582-12d6-46c5-d113-5f23205b615e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved project id\n",
            "Warning: TensorFlow Addons not found. Models that use non-standard ops may not work.\n",
            "Success: model at 'gs://elera_classificator/eeified_uni_model_3' is ready to be hosted in AI Platform.\n"
          ]
        }
      ],
      "source": [
        "# Put the EEified model next to the trained model directory.\n",
        "EEIFIED_DIR = 'gs://' + OUTPUT_BUCKET + '/eeified_uni_model_3'\n",
        "PROJECT = 'pd-psr-elera'\n",
        "SERVICE_ACC_JSON = 'pd-psr-elera-e8562bed1814.json'\n",
        "# You need to set the project before using the model prepare command.\n",
        "#!earthengine authenticate\n",
        "!earthengine set_project {PROJECT}\n",
        "!earthengine model prepare --source_dir {MODEL_DIR} --dest_dir {EEIFIED_DIR} --input {input_dict} --output {output_dict}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOEspqWO0xE8",
        "outputId": "afce8a59-ed64-4674-bf60-2d834edb5a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are authorizing gcloud CLI without access to a web browser. Please run the following command on a machine with a web browser and copy its output back here. Make sure the installed gcloud version is 372.0.0 or newer.\n",
            "\n",
            "gcloud auth login --remote-bootstrap=\"https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=hGD4I71W616fRKLFnE2e8bW7i5utnm&access_type=offline&code_challenge=68JnX51V23Tu8qPwA_y6D5S8t-cfzllSTqLdo4AcMFM&code_challenge_method=S256&token_usage=remote\"\n",
            "\n",
            "\n",
            "Enter the output of the above command: https://localhost:8085/?state=UnmnLjso15NrHQfkTr9EvoOgdUAdS1&code=4/0AX4XfWjFFe9reF3zD8l8rpQk2lP15EwePEOhi3MnX5IholmsZkQCRCuDaZPDunBmvQyVhg&scope=email%20openid%20https://www.googleapis.com/auth/userinfo.email%20https://www.googleapis.com/auth/cloud-platform%20https://www.googleapis.com/auth/appengine.admin%20https://www.googleapis.com/auth/compute%20https://www.googleapis.com/auth/accounts.reauth&authuser=0&hd=psr-inc.com&p\n",
            "\u001b[1;31mERROR:\u001b[0m gcloud crashed (MismatchingStateError): (mismatching_state) CSRF Warning! State not equal in request and response.\n",
            "\n",
            "If you would like to report this issue, please run the following command:\n",
            "  gcloud feedback\n",
            "\n",
            "To check gcloud for common problems, please run the following command:\n",
            "  gcloud info --run-diagnostics\n",
            "Updated property [core/project].\n",
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n",
            "Created ai platform model [projects/pd-psr-elera/models/uni_classifier_3].\n",
            "Using endpoint [https://us-central1-ml.googleapis.com/]\n"
          ]
        }
      ],
      "source": [
        "REGION = 'us-central1'\n",
        "\n",
        "MODEL_NAME = 'uni_classifier_3'\n",
        "VERSION_NAME = 'v0'\n",
        "\n",
        "#from google.cloud import storage\n",
        "#storage_client = storage.Client.from_service_account_json(SERVICE_ACC_JSON)\n",
        "\n",
        "! gcloud auth login #activate-service-account {SERV_ACC} --key-file={SERVICE_ACC_JSON}\n",
        "! gcloud config set project {PROJECT}\n",
        "!gcloud ai-platform models create {MODEL_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION}\n",
        "\n",
        "!gcloud ai-platform versions create {VERSION_NAME} \\\n",
        "  --project {PROJECT} \\\n",
        "  --region {REGION} \\\n",
        "  --model {MODEL_NAME} \\\n",
        "  --origin {EEIFIED_DIR} \\\n",
        "  --framework \"TENSORFLOW\" \\\n",
        "  --runtime-version=2.3 \\\n",
        "  --python-version=3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVgm9JZ5IVX9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "AOI = studyArea\n",
        "START_DATE = '2020-07-01'\n",
        "END_DATE = '2020-10-31'\n",
        "CLOUD_FILTER = 60\n",
        "CLD_PRB_THRESH = 50\n",
        "NIR_DRK_THRESH = 0.15\n",
        "CLD_PRJ_DIST = 1\n",
        "BUFFER = 50\n",
        "\n",
        "def get_s2_sr_cld_col(aoi, start_date, end_date):\n",
        "    # Import and filter S2 SR.\n",
        "    s2_sr_col = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(start_date, end_date)\n",
        "        .filter(ee.Filter.lte('CLOUDY_PIXEL_PERCENTAGE', CLOUD_FILTER)))\n",
        "\n",
        "    # Import and filter s2cloudless.\n",
        "    s2_cloudless_col = (ee.ImageCollection('COPERNICUS/S2_CLOUD_PROBABILITY')\n",
        "        .filterBounds(aoi)\n",
        "        .filterDate(start_date, end_date))\n",
        "\n",
        "    # Join the filtered s2cloudless collection to the SR collection by the 'system:index' property.\n",
        "    return ee.ImageCollection(ee.Join.saveFirst('s2cloudless').apply(**{\n",
        "        'primary': s2_sr_col,\n",
        "        'secondary': s2_cloudless_col,\n",
        "        'condition': ee.Filter.equals(**{\n",
        "            'leftField': 'system:index',\n",
        "            'rightField': 'system:index'\n",
        "        })\n",
        "    }))\n",
        "\n",
        "def add_cloud_bands(img):\n",
        "  # Get s2cloudless image, subset the probability band.\n",
        "  cld_prb = ee.Image(img.get('s2cloudless')).select('probability')\n",
        "\n",
        "  # Condition s2cloudless by the probability threshold value.\n",
        "  is_cloud = cld_prb.gt(CLD_PRB_THRESH).rename('clouds')\n",
        "\n",
        "  # Add the cloud probability layer and cloud mask as image bands.\n",
        "  return img.addBands(ee.Image([cld_prb, is_cloud]))\n",
        "\n",
        "def add_shadow_bands(img):\n",
        "    # Identify water pixels from the SCL band.\n",
        "    not_water = img.select('SCL').neq(6)\n",
        "\n",
        "    # Identify dark NIR pixels that are not water (potential cloud shadow pixels).\n",
        "    SR_BAND_SCALE = 1e4\n",
        "    dark_pixels = img.select('B8').lt(NIR_DRK_THRESH*SR_BAND_SCALE).multiply(not_water).rename('dark_pixels')\n",
        "\n",
        "    # Determine the direction to project cloud shadow from clouds (assumes UTM projection).\n",
        "    shadow_azimuth = ee.Number(90).subtract(ee.Number(img.get('MEAN_SOLAR_AZIMUTH_ANGLE')));\n",
        "\n",
        "    # Project shadows from clouds for the distance specified by the CLD_PRJ_DIST input.\n",
        "    cld_proj = (img.select('clouds').directionalDistanceTransform(shadow_azimuth, CLD_PRJ_DIST*10)\n",
        "        .reproject(**{'crs': img.select(0).projection(), 'scale': 100})\n",
        "        .select('distance')\n",
        "        .mask()\n",
        "        .rename('cloud_transform'))\n",
        "\n",
        "    # Identify the intersection of dark pixels with cloud shadow projection.\n",
        "    shadows = cld_proj.multiply(dark_pixels).rename('shadows')\n",
        "\n",
        "    # Add dark pixels, cloud projection, and identified shadows as image bands.\n",
        "    return img.addBands(ee.Image([dark_pixels, cld_proj, shadows]))\n",
        "\n",
        "def add_cld_shdw_mask(img):\n",
        "    # Add cloud component bands.\n",
        "    img_cloud = add_cloud_bands(img)\n",
        "\n",
        "    # Add cloud shadow component bands.\n",
        "    img_cloud_shadow = add_shadow_bands(img_cloud)\n",
        "\n",
        "    # Combine cloud and shadow mask, set cloud and shadow as value 1, else 0.\n",
        "    is_cld_shdw = img_cloud_shadow.select('clouds').add(img_cloud_shadow.select('shadows')).gt(0)\n",
        "\n",
        "    # Remove small cloud-shadow patches and dilate remaining pixels by BUFFER input.\n",
        "    # 20 m scale is for speed, and assumes clouds don't require 10 m precision.\n",
        "    is_cld_shdw = (is_cld_shdw.focalMin(2).focalMax(BUFFER*2/20)\n",
        "        .reproject(**{'crs': img.select([0]).projection(), 'scale': 20})\n",
        "        .rename('cloudmask'))\n",
        "\n",
        "    # Add the final cloud-shadow mask to the image.\n",
        "    return img_cloud_shadow.addBands(is_cld_shdw)\n",
        "\n",
        "def apply_cld_shdw_mask(img):\n",
        "    # Subset the cloudmask band and invert it so clouds/shadow are 0, else 1.\n",
        "    not_cld_shdw = img.select('cloudmask').Not()\n",
        "\n",
        "    # Subset reflectance bands and update their masks, return the result.\n",
        "    return img.select('B.*').updateMask(not_cld_shdw)\n",
        "\n",
        "def add_ee_layer(self, ee_image_object, vis_params, name, show=True, opacity=1, min_zoom=0):\n",
        "  map_id_dict = ee.Image(ee_image_object).getMapId(vis_params)\n",
        "  folium.raster_layers.TileLayer(\n",
        "      tiles=map_id_dict['tile_fetcher'].url_format,\n",
        "      attr='Map Data &copy; <a href=\"https://earthengine.google.com/\">Google Earth Engine</a>',\n",
        "      name=name,\n",
        "      show=show,\n",
        "      opacity=opacity,\n",
        "      min_zoom=min_zoom,\n",
        "      overlay=True,\n",
        "      control=True\n",
        "      ).add_to(self)\n",
        "\n",
        "# Add the Earth Engine layer method to folium.\n",
        "folium.Map.add_ee_layer = add_ee_layer"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Elera_tf_uni_3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
